import streamlit as st

st.set_page_config(
    page_title="Data Pipeline Overview",
    layout="wide"
)

st.title("ğŸ“Š Data Pipeline Overview")
st.markdown(
    """
This page explains **how data is collected, processed, enriched, and stored**
before being used for analysis and visualization.
"""
)

# =====================================================
# SECTION 1 â€” ARCHITECTURE
# =====================================================
st.header("ğŸ§± Data Architecture")

st.markdown("""
```text
AirLabs API  â”€â”€â”€â”€â”€â”€â”
                   â”‚
                   â–¼
            Python ETL Scripts
                   â”‚
Open-Meteo API â”€â”€â”€â”€â”˜
                   â–¼
              Supabase
                   â–¼
           Streamlit Dashboard
This project follows a modern data pipeline architecture:

External APIs provide raw data

Python handles extraction and transformation

Supabase stores cleaned and structured data

Streamlit displays analytics and insights
""")

=====================================================
SECTION 2 â€” DATA SOURCES
=====================================================

st.header("ğŸ“¡ Data Sources")

st.markdown("""

âœˆï¸ AirLabs API

Used to retrieve:

Flight number

Airline

Departure & arrival airports

Scheduled and actual times

Aircraft information

ğŸŒ¦ï¸ Open-Meteo API

Used to enrich each flight with:

Temperature

Wind speed

Visibility

Precipitation

Weather conditions (rain, fog, icing)

ğŸ—ºï¸ Airports Reference Table

Static dataset containing:

ICAO code

Airport name

Country

Latitude / Longitude
""")

=====================================================
SECTION 3 â€” DATA PROCESSING
=====================================================

st.header("âš™ï¸ Data Processing")

st.markdown("""
The ETL pipeline performs the following steps:

Extract

Fetch flights from AirLabs API

Fetch weather data from Open-Meteo

Transform

Normalize timestamps (UTC)

Match flights with nearest weather data

Create derived features:

is_rain

is_fog

is_icing

weather_severity

Load

Store data in Supabase (PostgreSQL)

Avoid duplicate inserts

Skip already enriched rows
""")

=====================================================
SECTION 4 â€” DATA MODEL
=====================================================

st.header("ğŸ—„ï¸ Data Model")

st.markdown("""

Main Table: flights_airlabs

Key fields:

flight_icao

airline_name

dep_icao, arr_icao

dep_time, arr_time

dep_delay, arr_delay

temperature

wind_speed

visibility

weather_severity

Reference Table:

airports_reference

airport name

latitude / longitude

country
""")

=====================================================
SECTION 5 â€” DATA QUALITY & SAFETY
=====================================================

st.header("ğŸ” Data Quality & Safety")

st.markdown("""
âœ” Duplicate prevention using unique constraints
âœ” Weather data fetched only if missing
âœ” API rate limits respected
âœ” Read-only access from Streamlit
âœ” Supabase Row Level Security (RLS) enabled

This ensures:

No accidental overwrite

No unnecessary API calls

Secure public dashboard access
""")

=====================================================
SECTION 6 â€” PROJECT GOALS
=====================================================

st.header("ğŸ¯ Project Objectives")

st.markdown("""
This project demonstrates:

âœ… End-to-end data engineering
âœ… API integration
âœ… Data enrichment
âœ… SQL + Python workflow
âœ… Analytics-ready dataset
âœ… Dashboard-oriented thinking

It is designed as a portfolio-grade project showcasing real-world data handling.
""")

st.success("âœ… Data Pipeline successfully documented.")
